{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274f061b-b28a-424a-8eee-d04110516814",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimization for Machine Learning and Deep Learning\n",
    "\n",
    "> We will start with linear regression model </br>\n",
    "> All the implementation will be done using OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1c41216-4f3b-405e-948d-50512667f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669f371-7c3f-4608-95a2-243372a2ca90",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implement the model using class and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba1d967e-1aa2-4aac-bea0-be32c29ba62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lin_reg:\n",
    "    \n",
    "   # initialize model variables \n",
    "    def __init__(self):\n",
    "        # Learning rate of the network\n",
    "        self.alpha = 0.0001\n",
    "        self.error = 1\n",
    "        self.df = None\n",
    "        self.scaling_type = 'norm'\n",
    "        \n",
    "        # 0o .....0n+1\n",
    "        self.params = None\n",
    "    \n",
    "    # Allow modifying of learning rate for diversity in application\n",
    "    def set_learning_rate(self, alpha):\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    # Allow modifying of scaling type\n",
    "    def set_scaling_type(self, scaling_type):\n",
    "        self.scaling_type = scaling_type\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # cleaning and scaling function\n",
    "    def norm_clean(self):\n",
    "        \n",
    "        # initialize 0s to 1 \n",
    "        self.params = np.array(np.ones(self.df.shape[1]))\n",
    "        \n",
    "        \n",
    "        # drop null values to avoid exceptions while processing \n",
    "        self.df.dropna()\n",
    "        \n",
    "        \n",
    "        # scale values depending on scaling type defined\n",
    "        if self.scaling_type == 'norm':\n",
    "            for col in self.df.columns:\n",
    "                self.df[col] = (self.df[col] - self.df[col].min()) / ( self.df[col].max() - self.df[col].min())\n",
    "        \n",
    "        elif self.scaling_type == 'mean':\n",
    "            for col in self.df.columns:\n",
    "                self.df[col] = (self.df[col] - self.df[col].mean()) / self.df[col].std()\n",
    "                \n",
    "        elif self.scaling_type == 'robust':\n",
    "            for col in self.dfcolumns:\n",
    "                self.df[col] = (self.df[col] - self.df[col].quantile(0.25)) / (self.df[col].quantile(0.75) - self.df[col].quantile(0.25))\n",
    "                \n",
    "        \n",
    "        \n",
    "    \n",
    "    # Read from df\n",
    "    def read_df(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        self.norm_clean()\n",
    "        \n",
    "    # Read from csv file \n",
    "    def read_csv(self, name):\n",
    "        self.df = pd.read_csv(name, names=[0,1])\n",
    "        \n",
    "        \n",
    "        self.norm_clean()\n",
    "\n",
    "    def print_df(self):\n",
    "        print(self.df.describe())\n",
    "    \n",
    "    \n",
    "    # Define error function\n",
    "    def error_calc(self):\n",
    "        sum = (( self.params[0] + self.df[0] * self.params[1] - self.df[1] ) ** 2).sum()\n",
    "        \n",
    "        self.error = sum / (float(2) * self.df.shape[0])\n",
    "        \n",
    "        \n",
    "    # Define gradient descent function\n",
    "    def grad_desc(self):\n",
    "        th0 = ( self.params[0] + self.df[0] * self.params[1] - self.df[1] ).sum() / self.df.shape[0]\n",
    "        th1 = ( (self.params[0] + self.df[0] * self.params[1] - self.df[1]) * self.df[0] ).sum() / self.df.shape[0]\n",
    "        \n",
    "        self.params[0] -= self.alpha * th0 * self.params[0]\n",
    "        self.params[1] -= self.alpha * th1 * self.params[1]\n",
    "       \n",
    "        \n",
    "    def train():\n",
    "        for i in range(50000):\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "model = lin_reg()\n",
    "\n",
    "model.read_csv('data.csv')\n",
    "model.error_calc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2339a46-73a0-4d51-9492-0eda9baeab75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
